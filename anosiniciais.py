import os
from dotenv import load_dotenv

# Carrega vari√°veis do .env da raiz do projeto
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))

# ==================================================================================
#                           CONFIGURA√á√ÉO DE PROXY
# ==================================================================================
# Configurar proxy para conex√µes externas (Hugging Face)
proxy_config = {
    'http': 'http://guilherme.saito:890484gS@10.10.30.9:3128',
    'https': 'http://guilherme.saito:890484gS@10.10.30.9:3128'  # Note: usando http:// mesmo para https
}

# Configurar vari√°veis de ambiente para o proxy
os.environ['HTTP_PROXY'] = proxy_config['http']
os.environ['HTTPS_PROXY'] = proxy_config['https']
os.environ['http_proxy'] = proxy_config['http']
os.environ['https_proxy'] = proxy_config['https']

# Configurar requests para usar proxy
import requests
requests.adapters.DEFAULT_RETRIES = 3

print("üîß Proxy configurado para acessar Hugging Face")

import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
import matplotlib
matplotlib.use('Agg')  # Garante que matplotlib s√≥ salve imagens, sem abrir janelas
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ==================================================================================
#                           CONFIGURA√á√ïES DIN√ÇMICAS
# ==================================================================================
CONFIGURACOES = {
    'NOTA_CORTE': 0.80,
    'ARQUIVO_BNCC': "bncc_df_anosiniciais.xlsx",
    'ARQUIVO_CURRICULO': "ANOSINICIAIS_curriculo_normalizado.xlsx",
    'MODELO_EMBEDDINGS': 'all-MiniLM-L6-v2',
    'MOSTRAR_TOP_MATCHES_TERMINAL': 10,
    'MOSTRAR_TOP_CORRESPONDENCIAS': 15,
    'PREFIXO_ARQUIVOS': f"corte_{int(0.80*100)}pct_",
    'GERAR_HEATMAP': True,
    'TAMANHO_HEATMAP': (20, 20),
}

CONFIGURACOES['PREFIXO_ARQUIVOS'] = f"corte_{int(CONFIGURACOES['NOTA_CORTE']*100)}pct_"

print("="*80)
print("üöÄ ANALISADOR DE SIMILARIDADE BNCC x CURR√çCULO MUNICIPAL")
print("="*80)
print(f"‚öôÔ∏è  CONFIGURA√á√ïES ATIVAS:")
print(f"   üìä Nota de corte: {CONFIGURACOES['NOTA_CORTE']*100}%")
print(f"   ü§ñ Modelo: {CONFIGURACOES['MODELO_EMBEDDINGS']}")
print(f"   üìÅ Prefixo arquivos: {CONFIGURACOES['PREFIXO_ARQUIVOS']}")
print("="*80)

# ==================================================================================
#                           PROCESSAMENTO DOS DADOS
# ==================================================================================

# Carregamento dos dados
try:
    bncc_df_inf = pd.read_excel(CONFIGURACOES['ARQUIVO_BNCC'])
    curriculo_df_inf = pd.read_excel(CONFIGURACOES['ARQUIVO_CURRICULO'])
    print(f"‚úÖ Dados carregados: {len(bncc_df_inf)} habilidades BNCC, {len(curriculo_df_inf)} habilidades curr√≠culo")
except Exception as e:
    print(f"‚ùå Erro ao carregar dados: {e}")
    raise

# Verifica√ß√£o das colunas necess√°rias nos DataFrames
def checar_colunas_bncc(df):
    colunas_necessarias = ['EIXO', 'HABILIDADE', 'EXEMPLOS']
    for col in colunas_necessarias:
        assert col in df.columns, f"BNCC deve ter a coluna '{col}'"
    print("‚úÖ Colunas verificadas na BNCC")

def checar_colunas_curriculo(df):
    colunas_necessarias = ['DISCIPLINA', 'HABILIDADES', 'ORIENTACOES_PEDAGOGICAS']
    for col in colunas_necessarias:
        assert col in df.columns, f"Curr√≠culo deve ter a coluna '{col}'"
    print("‚úÖ Colunas verificadas no Curr√≠culo")

checar_colunas_bncc(bncc_df_inf)
checar_colunas_curriculo(curriculo_df_inf)

# Normaliza os nomes das colunas para evitar problemas de espa√ßo/acentua√ß√£o
curriculo_df_inf.columns = curriculo_df_inf.columns.str.strip()
bncc_df_inf.columns = bncc_df_inf.columns.str.strip()

# ==================================================================================
#                    FUN√á√ÉO CORRIGIDA PARA EXTRAIR C√ìDIGOS
# ==================================================================================

def extrair_codigo(obj):
    """
    Extrai c√≥digos no formato (EI03CO01), (EF01CO01), etc.
    """
    if pd.isna(obj):
        return "(SEM_COD)"
    
    obj_str = str(obj)
    
    # Padr√£o mais robusto para capturar c√≥digos BNCC
    patterns = [
        r'\(([A-Z]{2}\d{2}[A-Z]{2}\d{2})\)',  # Padr√£o principal: EI03CO01
        r'\(([A-Z]+\d+[A-Z]*\d*)\)',          # Padr√£o mais geral
        r'\(([A-Z0-9]+)\)',                   # Padr√£o ainda mais geral
    ]
    
    for pattern in patterns:
        match = re.search(pattern, obj_str)
        if match:
            return f"({match.group(1)})"
    
    # Se n√£o encontrou nenhum padr√£o, tenta extrair qualquer coisa entre par√™nteses no in√≠cio
    match_inicio = re.search(r'^\(([^)]+)\)', obj_str)
    if match_inicio:
        return f"({match_inicio.group(1)})"
    
    # Como √∫ltimo recurso, pega os primeiros 15 caracteres + "..."
    return f"({obj_str[:15]}...)" if len(obj_str) > 15 else f"({obj_str})"

# Testar a fun√ß√£o de extra√ß√£o com alguns exemplos
print("\nüîç TESTE DA FUN√á√ÉO DE EXTRA√á√ÉO DE C√ìDIGOS:")
print("-" * 50)
for i in range(min(5, len(bncc_df_inf))):
    obj_original = bncc_df_inf['HABILIDADE'].iloc[i]
    codigo_extraido = extrair_codigo(obj_original)
    print(f"Original: {obj_original}")
    print(f"C√≥digo:   {codigo_extraido}")
    print("-" * 30)

# Fun√ß√£o para concatenar as features relevantes
def concat_features_bncc(df):
    return (
        df['EIXO'].astype(str) + " | " +
        df['HABILIDADE'].astype(str) + " | " +
        df['EXEMPLOS'].astype(str)
    )

def concat_features_curriculo(df):
    return (
        df['DISCIPLINA'].astype(str) + " | " +
        df['HABILIDADES'].astype(str) + " | " +
        df['ORIENTACOES_PEDAGOGICAS'].astype(str)
    )

bncc_texts = concat_features_bncc(bncc_df_inf)
curriculo_texts = concat_features_curriculo(curriculo_df_inf)

# Carregar modelo de embeddings
try:
    # Configura√ß√µes adicionais para contornar problemas de proxy/SSL
    if 'HUGGINGFACE_HUB_DISABLE_SYMLINKS' in os.environ:
        del os.environ['HUGGINGFACE_HUB_DISABLE_SYMLINKS']
    
    # Desabilitar verifica√ß√£o SSL se necess√°rio (apenas para ambientes corporativos)
    import ssl
    ssl._create_default_https_context = ssl._create_unverified_context
    
    # Configurar timeout maior para downloads
    os.environ['HF_HUB_TIMEOUT'] = '120'
    
    print(f"ü§ñ Carregando modelo {CONFIGURACOES['MODELO_EMBEDDINGS']}...")
    print("üì° Conectando atrav√©s do proxy corporativo...")
    
    model = SentenceTransformer(CONFIGURACOES['MODELO_EMBEDDINGS'])
    print("‚úÖ Modelo carregado com sucesso!")
except Exception as e:
    print(f"‚ùå Erro ao carregar o modelo: {e}")
    print("üí° Tentativas de solu√ß√£o:")
    print("   1. Verificar se o proxy est√° configurado corretamente")
    print("   2. Tentar usar o modelo offline se j√° foi baixado antes")
    print("   3. Verificar conectividade com a internet")
    
    # Tentar carregar um modelo local ou menor como fallback
    try:
        print("üîÑ Tentando modelo alternativo...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("‚úÖ Modelo alternativo carregado com sucesso!")
    except:
        raise Exception("N√£o foi poss√≠vel carregar nenhum modelo. Verifique a configura√ß√£o do proxy.")

# Gerar embeddings
try:
    print("üîÑ Gerando embeddings da BNCC...")
    bncc_embeddings = model.encode(bncc_texts.tolist(), show_progress_bar=True)
    print("üîÑ Gerando embeddings do curr√≠culo...")
    curriculo_embeddings = model.encode(curriculo_texts.tolist(), show_progress_bar=True)
    print("‚úÖ Embeddings gerados com sucesso!")
except Exception as e:
    print(f"‚ùå Erro ao gerar embeddings: {e}")
    raise

# Calcular similaridades
print("üîÑ Calculando similaridades...")
grau_similaridade = cosine_similarity(bncc_embeddings, curriculo_embeddings)
print("‚úÖ Similaridades calculadas!")

# ==================================================================================
#                           AN√ÅLISE E RELAT√ìRIOS COM BUSCA ADAPTATIVA
# ==================================================================================

def encontrar_similaridade_adaptativa(similaridades_bncc, nota_corte_inicial):
    """
    Encontra pelo menos uma similaridade, diminuindo a nota de corte se necess√°rio
    """
    nota_corte_atual = nota_corte_inicial
    indices_similares = np.where(similaridades_bncc >= nota_corte_atual)[0]
    
    # Se n√£o encontrou nada com a nota de corte inicial, vai diminuindo
    while len(indices_similares) == 0 and nota_corte_atual > 0.1:
        nota_corte_atual -= 0.01  # Diminui 1% por vez
        indices_similares = np.where(similaridades_bncc >= nota_corte_atual)[0]
    
    # Se ainda n√£o encontrou nada, pega pelo menos a melhor (mais similar)
    if len(indices_similares) == 0:
        idx_melhor = np.argmax(similaridades_bncc)
        indices_similares = np.array([idx_melhor])
        nota_corte_atual = similaridades_bncc[idx_melhor]
    
    return indices_similares, nota_corte_atual

NOTA_CORTE = CONFIGURACOES['NOTA_CORTE']
data_relatorio = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

print(f"üìä Gerando relat√≥rio com nota de corte inicial de {NOTA_CORTE*100}%...")
print("üîÑ Usando busca adaptativa para garantir pelo menos uma correspond√™ncia por habilidade...")

# Criar relat√≥rio detalhado
relatorio_completo = []
estatisticas = {
    'total_bncc': len(bncc_df_inf),
    'bncc_com_similaridade_original': 0,
    'bncc_com_similaridade_adaptativa': 0,
    'total_matches_acima_corte': 0,
    'notas_corte_usadas': [],
    'nota_corte_original': NOTA_CORTE,
    'modelo_usado': CONFIGURACOES['MODELO_EMBEDDINGS'],
    'data_analise': data_relatorio
}

for idx_bncc, linha_bncc in enumerate(bncc_df_inf.itertuples(index=False)):
    # Obter similaridades desta habilidade BNCC com todas do curr√≠culo
    similaridades_bncc = grau_similaridade[idx_bncc]
    
    # Usar busca adaptativa para encontrar pelo menos uma correspond√™ncia
    indices_similares, nota_corte_usada = encontrar_similaridade_adaptativa(similaridades_bncc, NOTA_CORTE)
    estatisticas['notas_corte_usadas'].append(nota_corte_usada)
    
    # CORRE√á√ÉO: Usar o √≠ndice direto do DataFrame
    objetivo_aprendizagem = bncc_df_inf['HABILIDADE'].iloc[idx_bncc]
    bncc_codigo = extrair_codigo(objetivo_aprendizagem)
    
    habilidade_bncc = {
        'bncc_indice': idx_bncc + 1,
        'bncc_codigo': bncc_codigo,
        'bncc_eixo': linha_bncc.EIXO,
        'bncc_objetivo': objetivo_aprendizagem,
        'bncc_exemplos': linha_bncc.EXEMPLOS,
        'habilidades_similares': [],
        'tem_similaridade_original': len(np.where(similaridades_bncc >= NOTA_CORTE)[0]) > 0,
        'nota_corte_usada': nota_corte_usada,
        'quantidade_similares': len(indices_similares),
        'maior_similaridade': np.max(similaridades_bncc) if len(similaridades_bncc) > 0 else 0
    }
    
    # Adicionar habilidades similares do curr√≠culo
    for idx_similar in indices_similares:
        linha_curriculo = curriculo_df_inf.iloc[idx_similar]
        curriculo_codigo = extrair_codigo(linha_curriculo['HABILIDADES'])
        
        habilidade_similar = {
            'curriculo_indice': idx_similar + 1,
            'curriculo_codigo': curriculo_codigo,
            'curriculo_eixo': linha_curriculo['DISCIPLINA'],
            'curriculo_objetivo': linha_curriculo['HABILIDADES'],
            'curriculo_exemplos': linha_curriculo['ORIENTACOES_PEDAGOGICAS'],
            'similaridade': similaridades_bncc[idx_similar]
        }
        habilidade_bncc['habilidades_similares'].append(habilidade_similar)
        
        # Contar apenas matches que atendem √† nota de corte original
        if similaridades_bncc[idx_similar] >= NOTA_CORTE:
            estatisticas['total_matches_acima_corte'] += 1
    
    # Ordenar por similaridade (maior primeiro)
    habilidade_bncc['habilidades_similares'].sort(key=lambda x: x['similaridade'], reverse=True)
    
    relatorio_completo.append(habilidade_bncc)
    
    # Atualizar estat√≠sticas
    if habilidade_bncc['tem_similaridade_original']:
        estatisticas['bncc_com_similaridade_original'] += 1
    
    # Todas as habilidades ter√£o pelo menos uma correspond√™ncia devido √† busca adaptativa
    estatisticas['bncc_com_similaridade_adaptativa'] += 1

print("‚úÖ Relat√≥rio analisado! Salvando arquivos...")

# Estat√≠sticas das notas de corte usadas
nota_corte_media = np.mean(estatisticas['notas_corte_usadas'])
nota_corte_min = np.min(estatisticas['notas_corte_usadas'])
nota_corte_max = np.max(estatisticas['notas_corte_usadas'])

print(f"üìà Estat√≠sticas da busca adaptativa:")
print(f"   Nota de corte m√©dia usada: {nota_corte_media:.1%}")
print(f"   Nota de corte m√≠nima: {nota_corte_min:.1%}")
print(f"   Nota de corte m√°xima: {nota_corte_max:.1%}")

# Verificar se os c√≥digos est√£o sendo extra√≠dos corretamente
print("\nüîç VERIFICA√á√ÉO FINAL DOS C√ìDIGOS EXTRA√çDOS:")
print("-" * 50)
for i in range(min(3, len(relatorio_completo))):
    hab = relatorio_completo[i]
    print(f"BNCC {i+1}: {hab['bncc_codigo']}")
    print(f"Objetivo: {hab['bncc_objetivo'][:80]}...")
    print(f"Nota de corte usada: {hab['nota_corte_usada']:.1%}")
    print(f"Similaridades encontradas: {hab['quantidade_similares']}")
    if hab['habilidades_similares']:
        print(f"Melhor match: {hab['habilidades_similares'][0]['curriculo_codigo']} ({hab['habilidades_similares'][0]['similaridade']:.1%})")
    print("-" * 30)

# ==================================================================================
#                           FUN√á√ïES DE GERA√á√ÉO DE RELAT√ìRIOS
# ==================================================================================

def gerar_relatorio_texto():
    relatorio_txt = f"""
==================================================================================
                    RELAT√ìRIO DE SIMILARIDADE BNCC x CURR√çCULO MUNICIPAL
==================================================================================
Data do relat√≥rio: {estatisticas['data_analise']}
Nota de corte inicial: {estatisticas['nota_corte_original']*100}% de similaridade
Modelo utilizado: {estatisticas['modelo_usado']}
Busca adaptativa: ATIVADA (garante pelo menos 1 correspond√™ncia por habilidade)

ESTAT√çSTICAS GERAIS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚Ä¢ Total de habilidades BNCC analisadas: {estatisticas['total_bncc']}
‚Ä¢ Habilidades BNCC com similaridade ‚â• {estatisticas['nota_corte_original']*100}% (nota original): {estatisticas['bncc_com_similaridade_original']} ({estatisticas['bncc_com_similaridade_original']/estatisticas['total_bncc']*100:.1f}%)
‚Ä¢ Habilidades BNCC com correspond√™ncia (busca adaptativa): {estatisticas['bncc_com_similaridade_adaptativa']} ({estatisticas['bncc_com_similaridade_adaptativa']/estatisticas['total_bncc']*100:.1f}%)
‚Ä¢ Total de matches acima da nota de corte original: {estatisticas['total_matches_acima_corte']}
‚Ä¢ Nota de corte m√©dia usada: {np.mean(estatisticas['notas_corte_usadas']):.1%}
‚Ä¢ Nota de corte m√≠nima usada: {np.min(estatisticas['notas_corte_usadas']):.1%}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

RELAT√ìRIO DETALHADO POR HABILIDADE BNCC:

"""
    
    for idx, habilidade in enumerate(relatorio_completo):
        relatorio_txt += f"""
{'='*80}
HABILIDADE BNCC #{habilidade['bncc_indice']} - {habilidade['bncc_codigo']}
{'='*80}

EIXO BNCC: {habilidade['bncc_eixo']}

OBJETIVO BNCC: {habilidade['bncc_objetivo']}

EXEMPLOS BNCC: {habilidade['bncc_exemplos']}

NOTA DE CORTE USADA: {habilidade['nota_corte_usada']:.1%} {'(original)' if habilidade['tem_similaridade_original'] else '(adaptativa)'}
QUANTIDADE DE HABILIDADES SIMILARES: {habilidade['quantidade_similares']}
MAIOR SIMILARIDADE ENCONTRADA: {habilidade['maior_similaridade']:.1%}

"""
        
        relatorio_txt += "HABILIDADES SIMILARES DO CURR√çCULO:\n"
        relatorio_txt += "-" * 60 + "\n"
        
        for i, similar in enumerate(habilidade['habilidades_similares'], 1):
            relatorio_txt += f"""
{i}. CURR√çCULO #{similar['curriculo_indice']} - {similar['curriculo_codigo']} | SIMILARIDADE: {similar['similaridade']:.1%}
   
   DISCIPLINA: {similar['curriculo_eixo']}
   
   HABILIDADE: {similar['curriculo_objetivo']}
   
   ORIENTA√á√ïES PEDAG√ìGICAS: {similar['curriculo_exemplos']}
   
   {'‚îÄ' * 50}
"""
    
    return relatorio_txt

def gerar_relatorio_csv():
    dados_csv = []
    
    for habilidade in relatorio_completo:
        # Com a busca adaptativa, todas as habilidades ter√£o pelo menos uma correspond√™ncia
        for similar in habilidade['habilidades_similares']:
            dados_csv.append({
                'BNCC_Indice': habilidade['bncc_indice'],
                'BNCC_Codigo': habilidade['bncc_codigo'],
                'BNCC_Eixo': habilidade['bncc_eixo'],
                'BNCC_Objetivo': habilidade['bncc_objetivo'],
                'BNCC_Exemplos': habilidade['bncc_exemplos'],
                'Curriculo_Indice': similar['curriculo_indice'],
                'Curriculo_Codigo': similar['curriculo_codigo'],
                'Curriculo_Eixo': similar['curriculo_eixo'],
                'Curriculo_Objetivo': similar['curriculo_objetivo'],
                'Curriculo_Exemplos': similar['curriculo_exemplos'],
                'Similaridade': similar['similaridade'],
                'Similaridade_Percentual': f"{similar['similaridade']:.1%}",
                'Nota_Corte_Usada': f"{habilidade['nota_corte_usada']:.1%}",
                'Busca_Adaptativa': 'N√£o' if habilidade['tem_similaridade_original'] else 'Sim',
                'Data_Analise': estatisticas['data_analise']
            })
    
    return pd.DataFrame(dados_csv)

def gerar_resumo_executivo():
    resumo = f"""
==================================================================================
                            RESUMO EXECUTIVO
==================================================================================
Data: {estatisticas['data_analise']}
Nota de corte inicial: {estatisticas['nota_corte_original']*100}%
Busca adaptativa: ATIVADA
Modelo: {estatisticas['modelo_usado']}

PRINCIPAIS DESCOBERTAS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚Ä¢ {estatisticas['bncc_com_similaridade_original']} de {estatisticas['total_bncc']} habilidades da BNCC ({estatisticas['bncc_com_similaridade_original']/estatisticas['total_bncc']*100:.1f}%) t√™m correspond√™ncia com nota de corte original ‚â• {estatisticas['nota_corte_original']*100}%

‚Ä¢ {estatisticas['bncc_com_similaridade_adaptativa']} de {estatisticas['total_bncc']} habilidades da BNCC ({estatisticas['bncc_com_similaridade_adaptativa']/estatisticas['total_bncc']*100:.1f}%) t√™m correspond√™ncia usando busca adaptativa

‚Ä¢ Total de {estatisticas['total_matches_acima_corte']} conex√µes identificadas acima da nota de corte original

‚Ä¢ Nota de corte m√©dia usada: {np.mean(estatisticas['notas_corte_usadas']):.1%}
‚Ä¢ Nota de corte m√≠nima usada: {np.min(estatisticas['notas_corte_usadas']):.1%}

HABILIDADES BNCC COM MAIOR N√öMERO DE CORRESPOND√äNCIAS:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""
    
    top_correspondencias = sorted(relatorio_completo, key=lambda x: x['quantidade_similares'], reverse=True)[:CONFIGURACOES['MOSTRAR_TOP_CORRESPONDENCIAS']]
    
    for i, hab in enumerate(top_correspondencias, 1):
        resumo += f"\n{i:2d}. {hab['bncc_codigo']} - {hab['quantidade_similares']} correspond√™ncias (m√°x: {hab['maior_similaridade']:.1%})"
        resumo += f"\n    {hab['bncc_eixo']}"
        resumo += f"\n    Nota de corte usada: {hab['nota_corte_usada']:.1%} {'(original)' if hab['tem_similaridade_original'] else '(adaptativa)'}"
    
    resumo += f"\n\nHABILIDADES QUE PRECISARAM DE BUSCA ADAPTATIVA:\n"
    resumo += "‚îÅ" * 70 + "\n"
    
    busca_adaptativa = [h for h in relatorio_completo if not h['tem_similaridade_original']]
    for hab in busca_adaptativa:
        resumo += f"\n‚Ä¢ {hab['bncc_codigo']} - {hab['bncc_eixo']}"
        resumo += f"\n  Nota de corte usada: {hab['nota_corte_usada']:.1%}"
        resumo += f"\n  M√°x. similaridade: {hab['maior_similaridade']:.1%}"
        resumo += f"\n  {hab['bncc_objetivo'][:100]}{'...' if len(hab['bncc_objetivo']) > 100 else ''}\n"
    
    return resumo

# ==================================================================================
#                           SALVAMENTO DOS ARQUIVOS
# ==================================================================================

# Criar pasta docs se n√£o existir
docs_path = "docs"
if not os.path.exists(docs_path):
    os.makedirs(docs_path)
    print(f"üìÅ Pasta '{docs_path}' criada para organizar os relat√≥rios")

nome_relatorio_completo = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}relatorio_completo.txt")
nome_relatorio_csv = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}relatorio.csv")
nome_resumo = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}resumo_executivo.txt")
nome_heatmap = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}heatmap_similaridade.png")

try:
    # Relat√≥rio completo em texto
    with open(nome_relatorio_completo, "w", encoding="utf-8") as f:
        f.write(gerar_relatorio_texto())
    
    # Relat√≥rio em CSV
    df_csv = gerar_relatorio_csv()
    df_csv.to_csv(nome_relatorio_csv, index=False, encoding="utf-8-sig")
    
    # Resumo executivo
    with open(nome_resumo, "w", encoding="utf-8") as f:
        f.write(gerar_resumo_executivo())
    
    print("‚úÖ Relat√≥rios salvos com sucesso!")
    print(f"   üìÑ {nome_relatorio_completo} - Relat√≥rio detalhado completo")
    print(f"   üìä {nome_relatorio_csv} - Dados em formato CSV")
    print(f"   üìã {nome_resumo} - Resumo com principais descobertas")
    
except Exception as e:
    print(f"‚ùå Erro ao salvar relat√≥rios: {e}")

# Gerar heatmap se configurado
if CONFIGURACOES['GERAR_HEATMAP']:
    try:
        # Extrai c√≥digos para usar como √≠ndices (usando as colunas corretas)
        bncc_codigos = bncc_df_inf['HABILIDADE'].apply(extrair_codigo).tolist()
        curriculo_codigos = curriculo_df_inf['HABILIDADES'].apply(extrair_codigo).tolist()
        
        # Cria DataFrame de similaridade
        sim_df = pd.DataFrame(grau_similaridade, 
                              index=bncc_codigos,
                              columns=curriculo_codigos)
        
        # Gera heatmap com tamanho configur√°vel
        tamanho_h, tamanho_c = CONFIGURACOES['TAMANHO_HEATMAP']
        plt.figure(figsize=(16, 10))
        sns.heatmap(
            sim_df.iloc[:tamanho_h, :tamanho_c],
            annot=True,
            fmt=".2f",
            cmap="Blues",
            vmin=0, vmax=1,
            cbar_kws={'label': 'Similaridade'}
        )
        plt.title(f"Heatmap de Similaridade BNCC x Curr√≠culo Municipal\nNota de corte: {CONFIGURACOES['NOTA_CORTE']*100}%")
        plt.xlabel("Curr√≠culo (c√≥digos)")
        plt.ylabel("BNCC (c√≥digos)")
        plt.tight_layout()
        plt.savefig(nome_heatmap, dpi=300, bbox_inches='tight')
        print(f"   üé® {nome_heatmap} - Heatmap de similaridade")
    except Exception as e:
        print(f"‚ö†Ô∏è  Aviso: N√£o foi poss√≠vel gerar o heatmap: {e}")

# ==================================================================================
#                           EXIBI√á√ÉO NO TERMINAL
# ==================================================================================

# Exibir resumo no terminal
print("\n" + "="*80)
print("üìä RESUMO DA AN√ÅLISE:")
print("="*80)
print(f"‚úÖ An√°lise conclu√≠da com sucesso!")
print(f"‚öôÔ∏è  Nota de corte inicial: {CONFIGURACOES['NOTA_CORTE']*100}%")
print(f"üìä {estatisticas['bncc_com_similaridade_original']}/{estatisticas['total_bncc']} habilidades BNCC t√™m correspond√™ncia ‚â• {CONFIGURACOES['NOTA_CORTE']*100}%")
print(f"ÔøΩ {estatisticas['bncc_com_similaridade_adaptativa']}/{estatisticas['total_bncc']} habilidades BNCC t√™m correspond√™ncia com busca adaptativa")
print(f"ÔøΩüîç {estatisticas['total_matches_acima_corte']} conex√µes identificadas acima da nota de corte original")
print(f"üìà Nota de corte m√©dia usada: {np.mean(estatisticas['notas_corte_usadas']):.1%}")
print(f"üìâ Nota de corte m√≠nima usada: {np.min(estatisticas['notas_corte_usadas']):.1%}")

# Mostrar algumas das melhores correspond√™ncias no terminal
print(f"\nüèÜ TOP {CONFIGURACOES['MOSTRAR_TOP_MATCHES_TERMINAL']} MELHORES CORRESPOND√äNCIAS:")
print("-" * 70)

todos_matches = []
for hab in relatorio_completo:
    for similar in hab['habilidades_similares']:
        todos_matches.append({
            'bncc_codigo': hab['bncc_codigo'],
            'curriculo_codigo': similar['curriculo_codigo'],
            'similaridade': similar['similaridade'],
            'bncc_eixo': hab['bncc_eixo'],
            'curriculo_eixo': similar['curriculo_eixo']
        })

top_matches = sorted(todos_matches, key=lambda x: x['similaridade'], reverse=True)[:CONFIGURACOES['MOSTRAR_TOP_MATCHES_TERMINAL']]

for i, match in enumerate(top_matches, 1):
    print(f"{i:2d}. {match['bncc_codigo']} ‚Üî {match['curriculo_codigo']} | {match['similaridade']:.1%}")
    print(f"    BNCC: {match['bncc_eixo']}")
    print(f"    Curr√≠culo: {match['curriculo_eixo']}")
    print()

print("="*80)
print("üí° DICA: Para alterar a nota de corte inicial, modifique CONFIGURACOES['NOTA_CORTE'] no topo do script!")
print("üîß A busca adaptativa garante que toda habilidade BNCC tenha pelo menos uma correspond√™ncia!")
print("üìÅ Consulte os arquivos de relat√≥rio para an√°lise completa!")
print("="*80)