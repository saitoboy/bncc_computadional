import os
from dotenv import load_dotenv

# Carrega variÃ¡veis do .env da raiz do projeto
load_dotenv(dotenv_path=os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))

# ==================================================================================
#                           CONFIGURAÃ‡ÃƒO DE PROXY
# ==================================================================================
# Configurar proxy para conexÃµes externas (Hugging Face)
proxy_config = {
    'http': 'http://guilherme.saito:890484gS@10.10.30.9:3128',
    'https': 'http://guilherme.saito:890484gS@10.10.30.9:3128'  # Note: usando http:// mesmo para https
}

# Configurar variÃ¡veis de ambiente para o proxy
os.environ['HTTP_PROXY'] = proxy_config['http']
os.environ['HTTPS_PROXY'] = proxy_config['https']
os.environ['http_proxy'] = proxy_config['http']
os.environ['https_proxy'] = proxy_config['https']

# Configurar requests para usar proxy
import requests
requests.adapters.DEFAULT_RETRIES = 3

print("ğŸ”§ Proxy configurado para acessar Hugging Face")

import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re
import matplotlib
matplotlib.use('Agg')  # Garante que matplotlib sÃ³ salve imagens, sem abrir janelas
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ==================================================================================
#                           CONFIGURAÃ‡Ã•ES DINÃ‚MICAS
# ==================================================================================
CONFIGURACOES = {
    'NOTA_CORTE': 0.80,
    'ARQUIVO_BNCC': "bncc_df_anosiniciais.xlsx",
    'ARQUIVO_CURRICULO': "ANOSINICIAIS_curriculo_normalizado.xlsx",
    'MODELO_EMBEDDINGS': 'all-MiniLM-L6-v2',
    'MOSTRAR_TOP_MATCHES_TERMINAL': 10,
    'MOSTRAR_TOP_CORRESPONDENCIAS': 15,
    'PREFIXO_ARQUIVOS': f"corte_{int(0.80*100)}pct_",
    'GERAR_HEATMAP': True,
    'TAMANHO_HEATMAP': (20, 20),
}

CONFIGURACOES['PREFIXO_ARQUIVOS'] = f"corte_{int(CONFIGURACOES['NOTA_CORTE']*100)}pct_"

print("="*80)
print("ğŸš€ ANALISADOR DE SIMILARIDADE BNCC x CURRÃCULO MUNICIPAL")
print("="*80)
print(f"âš™ï¸  CONFIGURAÃ‡Ã•ES ATIVAS:")
print(f"   ğŸ“Š Nota de corte: {CONFIGURACOES['NOTA_CORTE']*100}%")
print(f"   ğŸ¤– Modelo: {CONFIGURACOES['MODELO_EMBEDDINGS']}")
print(f"   ğŸ“ Prefixo arquivos: {CONFIGURACOES['PREFIXO_ARQUIVOS']}")
print("="*80)

# ==================================================================================
#                           PROCESSAMENTO DOS DADOS
# ==================================================================================

# Carregamento dos dados
try:
    bncc_df_inf = pd.read_excel(CONFIGURACOES['ARQUIVO_BNCC'])
    curriculo_df_inf = pd.read_excel(CONFIGURACOES['ARQUIVO_CURRICULO'])
    print(f"âœ… Dados carregados: {len(bncc_df_inf)} habilidades BNCC, {len(curriculo_df_inf)} habilidades currÃ­culo")
except Exception as e:
    print(f"âŒ Erro ao carregar dados: {e}")
    raise

# VerificaÃ§Ã£o das colunas necessÃ¡rias nos DataFrames
def checar_colunas_bncc(df):
    colunas_necessarias = ['EIXO', 'HABILIDADE', 'EXEMPLOS']
    for col in colunas_necessarias:
        assert col in df.columns, f"BNCC deve ter a coluna '{col}'"
    print("âœ… Colunas verificadas na BNCC")

def checar_colunas_curriculo(df):
    colunas_necessarias = ['DISCIPLINA', 'HABILIDADES', 'ORIENTACOES_PEDAGOGICAS']
    for col in colunas_necessarias:
        assert col in df.columns, f"CurrÃ­culo deve ter a coluna '{col}'"
    print("âœ… Colunas verificadas no CurrÃ­culo")

checar_colunas_bncc(bncc_df_inf)
checar_colunas_curriculo(curriculo_df_inf)

# Normaliza os nomes das colunas para evitar problemas de espaÃ§o/acentuaÃ§Ã£o
curriculo_df_inf.columns = curriculo_df_inf.columns.str.strip()
bncc_df_inf.columns = bncc_df_inf.columns.str.strip()

# ==================================================================================
#                    FUNÃ‡ÃƒO CORRIGIDA PARA EXTRAIR CÃ“DIGOS
# ==================================================================================

def extrair_codigo(obj):
    """
    Extrai cÃ³digos no formato (EI03CO01), (EF01CO01), etc.
    """
    if pd.isna(obj):
        return "(SEM_COD)"
    
    obj_str = str(obj)
    
    # PadrÃ£o mais robusto para capturar cÃ³digos BNCC
    patterns = [
        r'\(([A-Z]{2}\d{2}[A-Z]{2}\d{2})\)',  # PadrÃ£o principal: EI03CO01
        r'\(([A-Z]+\d+[A-Z]*\d*)\)',          # PadrÃ£o mais geral
        r'\(([A-Z0-9]+)\)',                   # PadrÃ£o ainda mais geral
    ]
    
    for pattern in patterns:
        match = re.search(pattern, obj_str)
        if match:
            return f"({match.group(1)})"
    
    # Se nÃ£o encontrou nenhum padrÃ£o, tenta extrair qualquer coisa entre parÃªnteses no inÃ­cio
    match_inicio = re.search(r'^\(([^)]+)\)', obj_str)
    if match_inicio:
        return f"({match_inicio.group(1)})"
    
    # Como Ãºltimo recurso, pega os primeiros 15 caracteres + "..."
    return f"({obj_str[:15]}...)" if len(obj_str) > 15 else f"({obj_str})"

# Testar a funÃ§Ã£o de extraÃ§Ã£o com alguns exemplos
print("\nğŸ” TESTE DA FUNÃ‡ÃƒO DE EXTRAÃ‡ÃƒO DE CÃ“DIGOS:")
print("-" * 50)
for i in range(min(5, len(bncc_df_inf))):
    obj_original = bncc_df_inf['HABILIDADE'].iloc[i]
    codigo_extraido = extrair_codigo(obj_original)
    print(f"Original: {obj_original}")
    print(f"CÃ³digo:   {codigo_extraido}")
    print("-" * 30)

# FunÃ§Ã£o para concatenar as features relevantes
def concat_features_bncc(df):
    return (
        df['EIXO'].astype(str) + " | " +
        df['HABILIDADE'].astype(str) + " | " +
        df['EXEMPLOS'].astype(str)
    )

def concat_features_curriculo(df):
    return (
        df['DISCIPLINA'].astype(str) + " | " +
        df['HABILIDADES'].astype(str) + " | " +
        df['ORIENTACOES_PEDAGOGICAS'].astype(str)
    )

bncc_texts = concat_features_bncc(bncc_df_inf)
curriculo_texts = concat_features_curriculo(curriculo_df_inf)

# Carregar modelo de embeddings
try:
    # ConfiguraÃ§Ãµes adicionais para contornar problemas de proxy/SSL
    if 'HUGGINGFACE_HUB_DISABLE_SYMLINKS' in os.environ:
        del os.environ['HUGGINGFACE_HUB_DISABLE_SYMLINKS']
    
    # Desabilitar verificaÃ§Ã£o SSL se necessÃ¡rio (apenas para ambientes corporativos)
    import ssl
    ssl._create_default_https_context = ssl._create_unverified_context
    
    # Configurar timeout maior para downloads
    os.environ['HF_HUB_TIMEOUT'] = '120'
    
    print(f"ğŸ¤– Carregando modelo {CONFIGURACOES['MODELO_EMBEDDINGS']}...")
    print("ğŸ“¡ Conectando atravÃ©s do proxy corporativo...")
    
    model = SentenceTransformer(CONFIGURACOES['MODELO_EMBEDDINGS'])
    print("âœ… Modelo carregado com sucesso!")
except Exception as e:
    print(f"âŒ Erro ao carregar o modelo: {e}")
    print("ğŸ’¡ Tentativas de soluÃ§Ã£o:")
    print("   1. Verificar se o proxy estÃ¡ configurado corretamente")
    print("   2. Tentar usar o modelo offline se jÃ¡ foi baixado antes")
    print("   3. Verificar conectividade com a internet")
    
    # Tentar carregar um modelo local ou menor como fallback
    try:
        print("ğŸ”„ Tentando modelo alternativo...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("âœ… Modelo alternativo carregado com sucesso!")
    except:
        raise Exception("NÃ£o foi possÃ­vel carregar nenhum modelo. Verifique a configuraÃ§Ã£o do proxy.")

# Gerar embeddings
try:
    print("ğŸ”„ Gerando embeddings da BNCC...")
    bncc_embeddings = model.encode(bncc_texts.tolist(), show_progress_bar=True)
    print("ğŸ”„ Gerando embeddings do currÃ­culo...")
    curriculo_embeddings = model.encode(curriculo_texts.tolist(), show_progress_bar=True)
    print("âœ… Embeddings gerados com sucesso!")
except Exception as e:
    print(f"âŒ Erro ao gerar embeddings: {e}")
    raise

# Calcular similaridades
print("ğŸ”„ Calculando similaridades...")
grau_similaridade = cosine_similarity(bncc_embeddings, curriculo_embeddings)
print("âœ… Similaridades calculadas!")

# ==================================================================================
#                           ANÃLISE E RELATÃ“RIOS COM BUSCA ADAPTATIVA
# ==================================================================================

def encontrar_similaridade_balanceada(grau_similaridade, bncc_df, curriculo_df, nota_corte_inicial):
    """
    Encontra similaridades balanceadas por disciplina, evitando duplicatas
    """
    relatorio_completo = []
    habilidades_ja_usadas = set()  # Rastrear cÃ³digos jÃ¡ utilizados
    
    # Agrupar currÃ­culo por disciplina
    disciplinas_curriculo = {}
    for idx, linha in enumerate(curriculo_df.itertuples(index=False)):
        disciplina = getattr(linha, 'DISCIPLINA', getattr(linha, 'EIXO', 'SEM_DISCIPLINA'))
        if disciplina not in disciplinas_curriculo:
            disciplinas_curriculo[disciplina] = []
        
        # Extrair cÃ³digo da habilidade do currÃ­culo
        if hasattr(linha, 'HABILIDADES'):
            codigo = extrair_codigo(linha.HABILIDADES)
        elif hasattr(linha, 'OBJETIVO_DE_APRENDIZAGEM'):
            codigo = extrair_codigo(linha.OBJETIVO_DE_APRENDIZAGEM)
        else:
            codigo = f"CURR_{idx}"
            
        disciplinas_curriculo[disciplina].append({
            'indice': idx,
            'codigo': codigo,
            'linha': linha
        })
    
    print(f"ğŸ¯ Disciplinas encontradas: {list(disciplinas_curriculo.keys())}")
    print(f"ğŸ“Š DistribuiÃ§Ã£o por disciplina: {[(d, len(h)) for d, h in disciplinas_curriculo.items()]}")
    
    # Para cada habilidade BNCC
    for idx_bncc, linha_bncc in enumerate(bncc_df.itertuples(index=False)):
        similaridades_bncc = grau_similaridade[idx_bncc]
        
        # Extrair cÃ³digo BNCC
        if hasattr(linha_bncc, 'HABILIDADE'):
            bncc_codigo = extrair_codigo(linha_bncc.HABILIDADE)
            bncc_objetivo = linha_bncc.HABILIDADE
        elif hasattr(linha_bncc, 'OBJETIVO_DE_APRENDIZAGEM'):
            bncc_codigo = extrair_codigo(linha_bncc.OBJETIVO_DE_APRENDIZAGEM)
            bncc_objetivo = linha_bncc.OBJETIVO_DE_APRENDIZAGEM
        else:
            bncc_codigo = f"BNCC_{idx_bncc}"
            bncc_objetivo = "OBJETIVO NÃƒO ENCONTRADO"
        
        # Buscar melhores correspondÃªncias por disciplina
        correspondencias_por_disciplina = {}
        
        for disciplina, habilidades_disc in disciplinas_curriculo.items():
            melhores_da_disciplina = []
            
            for hab_curriculo in habilidades_disc:
                idx_curr = hab_curriculo['indice']
                codigo_curr = hab_curriculo['codigo']
                
                # Pular se jÃ¡ foi usado
                if codigo_curr in habilidades_ja_usadas:
                    continue
                
                similaridade = similaridades_bncc[idx_curr]
                melhores_da_disciplina.append({
                    'indice': idx_curr,
                    'codigo': codigo_curr,
                    'similaridade': similaridade,
                    'linha': hab_curriculo['linha'],
                    'disciplina': disciplina
                })
            
            # Ordenar por similaridade (maior primeiro)
            melhores_da_disciplina.sort(key=lambda x: x['similaridade'], reverse=True)
            correspondencias_por_disciplina[disciplina] = melhores_da_disciplina
        
        # Aplicar estratÃ©gia de distribuiÃ§Ã£o balanceada
        habilidades_similares = []
        nota_corte_usada = nota_corte_inicial
        
        # ESTRATÃ‰GIA 1: Tentar pegar a melhor de cada disciplina com nota de corte original
        for disciplina, candidatos in correspondencias_por_disciplina.items():
            if candidatos and candidatos[0]['similaridade'] >= nota_corte_inicial:
                melhor = candidatos[0]
                habilidades_similares.append(melhor)
                habilidades_ja_usadas.add(melhor['codigo'])
        
        # ESTRATÃ‰GIA 2: Se nÃ£o conseguiu nenhuma, usar busca adaptativa
        if not habilidades_similares:
            nota_corte_atual = nota_corte_inicial
            
            while not habilidades_similares and nota_corte_atual > 0.1:
                nota_corte_atual -= 0.01
                
                # Tentar pegar pelo menos uma de cada disciplina
                for disciplina, candidatos in correspondencias_por_disciplina.items():
                    for candidato in candidatos:
                        if (candidato['similaridade'] >= nota_corte_atual and 
                            candidato['codigo'] not in habilidades_ja_usadas):
                            habilidades_similares.append(candidato)
                            habilidades_ja_usadas.add(candidato['codigo'])
                            break  # SÃ³ uma por disciplina
                
                if habilidades_similares:
                    nota_corte_usada = nota_corte_atual
                    break
        
        # ESTRATÃ‰GIA 3: Se ainda nÃ£o tem nada, pegar pelo menos a melhor geral disponÃ­vel
        if not habilidades_similares:
            todas_opcoes = []
            for disciplina, candidatos in correspondencias_por_disciplina.items():
                for candidato in candidatos:
                    if candidato['codigo'] not in habilidades_ja_usadas:
                        todas_opcoes.append(candidato)
            
            if todas_opcoes:
                melhor_geral = max(todas_opcoes, key=lambda x: x['similaridade'])
                habilidades_similares.append(melhor_geral)
                habilidades_ja_usadas.add(melhor_geral['codigo'])
                nota_corte_usada = melhor_geral['similaridade']
        
        # ESTRATÃ‰GIA 4: Adicionar mais correspondÃªncias se houver espaÃ§o (mÃ¡ximo 3 por habilidade BNCC)
        if len(habilidades_similares) < 3:
            for disciplina, candidatos in correspondencias_por_disciplina.items():
                if len(habilidades_similares) >= 3:
                    break
                    
                for candidato in candidatos[1:]:  # Pular o primeiro (jÃ¡ foi considerado)
                    if (candidato['codigo'] not in habilidades_ja_usadas and 
                        candidato['similaridade'] >= nota_corte_usada * 0.9):  # 90% da nota de corte usada
                        habilidades_similares.append(candidato)
                        habilidades_ja_usadas.add(candidato['codigo'])
                        break
        
        # Ordenar por similaridade
        habilidades_similares.sort(key=lambda x: x['similaridade'], reverse=True)
        
        # Montar estrutura do relatÃ³rio
        habilidade_bncc = {
            'bncc_indice': idx_bncc + 1,
            'bncc_codigo': bncc_codigo,
            'bncc_eixo': linha_bncc.EIXO,
            'bncc_objetivo': bncc_objetivo,
            'bncc_exemplos': getattr(linha_bncc, 'EXEMPLOS', 'N/A'),
            'habilidades_similares': [],
            'tem_similaridade_original': any(h['similaridade'] >= nota_corte_inicial for h in habilidades_similares),
            'nota_corte_usada': nota_corte_usada,
            'quantidade_similares': len(habilidades_similares),
            'maior_similaridade': max([h['similaridade'] for h in habilidades_similares]) if habilidades_similares else 0,
            'disciplinas_envolvidas': len(set(h['disciplina'] for h in habilidades_similares))
        }
        
        # Adicionar detalhes das habilidades similares
        for similar in habilidades_similares:
            linha_curriculo = similar['linha']
            
            # Detectar coluna de habilidade do currÃ­culo
            if hasattr(linha_curriculo, 'HABILIDADES'):
                curriculo_objetivo = linha_curriculo.HABILIDADES
                curriculo_exemplos = getattr(linha_curriculo, 'ORIENTACOES_PEDAGOGICAS', 'N/A')
            elif hasattr(linha_curriculo, 'OBJETIVO_DE_APRENDIZAGEM'):
                curriculo_objetivo = linha_curriculo.OBJETIVO_DE_APRENDIZAGEM
                curriculo_exemplos = getattr(linha_curriculo, 'EXEMPLOS', 'N/A')
            else:
                curriculo_objetivo = "OBJETIVO NÃƒO ENCONTRADO"
                curriculo_exemplos = "N/A"
            
            habilidade_similar = {
                'curriculo_indice': similar['indice'] + 1,
                'curriculo_codigo': similar['codigo'],
                'curriculo_eixo': similar['disciplina'],
                'curriculo_objetivo': curriculo_objetivo,
                'curriculo_exemplos': curriculo_exemplos,
                'similaridade': similar['similaridade']
            }
            habilidade_bncc['habilidades_similares'].append(habilidade_similar)
        
        relatorio_completo.append(habilidade_bncc)
        
        # Log de progresso
        if (idx_bncc + 1) % 10 == 0:
            print(f"ğŸ“ˆ Processadas {idx_bncc + 1}/{len(bncc_df)} habilidades BNCC")
    
    # EstatÃ­sticas finais
    total_habilidades_usadas = len(habilidades_ja_usadas)
    total_habilidades_curriculo = len(curriculo_df)
    
    print(f"\nğŸ“Š ESTATÃSTICAS DE DISTRIBUIÃ‡ÃƒO:")
    print(f"   ğŸ¯ Habilidades do currÃ­culo utilizadas: {total_habilidades_usadas}/{total_habilidades_curriculo} ({total_habilidades_usadas/total_habilidades_curriculo*100:.1f}%)")
    print(f"   ğŸš« Habilidades nÃ£o utilizadas: {total_habilidades_curriculo - total_habilidades_usadas}")
    
    # EstatÃ­sticas por disciplina
    disciplinas_usadas = {}
    for hab_bncc in relatorio_completo:
        for similar in hab_bncc['habilidades_similares']:
            disc = similar['curriculo_eixo']
            disciplinas_usadas[disc] = disciplinas_usadas.get(disc, 0) + 1
    
    print(f"   ğŸ“š DistribuiÃ§Ã£o de uso por disciplina:")
    for disc, count in sorted(disciplinas_usadas.items()):
        total_disc = len(disciplinas_curriculo.get(disc, []))
        percentual = count/total_disc*100 if total_disc > 0 else 0
        print(f"      {disc}: {count}/{total_disc} ({percentual:.1f}%)")
    
    return relatorio_completo

def encontrar_similaridade_adaptativa(similaridades_bncc, nota_corte_inicial):
    """
    FunÃ§Ã£o mantida para compatibilidade - DEPRECADA
    Use encontrar_similaridade_balanceada() para melhor distribuiÃ§Ã£o
    """
    nota_corte_atual = nota_corte_inicial
    indices_similares = np.where(similaridades_bncc >= nota_corte_atual)[0]
    
    # Se nÃ£o encontrou nada com a nota de corte inicial, vai diminuindo
    while len(indices_similares) == 0 and nota_corte_atual > 0.1:
        nota_corte_atual -= 0.01  # Diminui 1% por vez
        indices_similares = np.where(similaridades_bncc >= nota_corte_atual)[0]
    
    # Se ainda nÃ£o encontrou nada, pega pelo menos a melhor (mais similar)
    if len(indices_similares) == 0:
        idx_melhor = np.argmax(similaridades_bncc)
        indices_similares = np.array([idx_melhor])
        nota_corte_atual = similaridades_bncc[idx_melhor]
    
    return indices_similares, nota_corte_atual

NOTA_CORTE = CONFIGURACOES['NOTA_CORTE']
data_relatorio = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

print(f"ğŸ“Š Gerando relatÃ³rio com nota de corte inicial de {NOTA_CORTE*100}%...")
print("ğŸ”„ Usando algoritmo balanceado para distribuiÃ§Ã£o por disciplinas...")
print("ğŸš« Evitando habilidades duplicadas (cÃ³digos Ãºnicos)...")

# EstatÃ­sticas
estatisticas = {
    'total_bncc': len(bncc_df_inf),
    'bncc_com_similaridade_original': 0,
    'bncc_com_similaridade_adaptativa': 0,
    'total_matches_acima_corte': 0,
    'notas_corte_usadas': [],
    'nota_corte_original': NOTA_CORTE,
    'modelo_usado': CONFIGURACOES['MODELO_EMBEDDINGS'],
    'data_analise': data_relatorio
}

# Usar nova funÃ§Ã£o balanceada
relatorio_completo = encontrar_similaridade_balanceada(
    grau_similaridade, 
    bncc_df_inf, 
    curriculo_df_inf, 
    NOTA_CORTE
)

# Calcular estatÃ­sticas do relatÃ³rio gerado
for habilidade in relatorio_completo:
    # Contar habilidades com similaridade original
    if habilidade['tem_similaridade_original']:
        estatisticas['bncc_com_similaridade_original'] += 1
    
    # Todas as habilidades terÃ£o pelo menos uma correspondÃªncia devido ao algoritmo balanceado
    estatisticas['bncc_com_similaridade_adaptativa'] += 1
    
    # Contar matches acima da nota de corte original
    for similar in habilidade['habilidades_similares']:
        if similar['similaridade'] >= NOTA_CORTE:
            estatisticas['total_matches_acima_corte'] += 1
    
    # Adicionar nota de corte usada para estatÃ­sticas
    estatisticas['notas_corte_usadas'].append(habilidade['nota_corte_usada'])

print("âœ… RelatÃ³rio analisado! Salvando arquivos...")

# EstatÃ­sticas das notas de corte usadas
nota_corte_media = np.mean(estatisticas['notas_corte_usadas'])
nota_corte_min = np.min(estatisticas['notas_corte_usadas'])
nota_corte_max = np.max(estatisticas['notas_corte_usadas'])

print(f"ğŸ“ˆ EstatÃ­sticas da busca balanceada:")
print(f"   Nota de corte mÃ©dia usada: {nota_corte_media:.1%}")
print(f"   Nota de corte mÃ­nima: {nota_corte_min:.1%}")
print(f"   Nota de corte mÃ¡xima: {nota_corte_max:.1%}")

# Verificar distribuiÃ§Ã£o por disciplinas
disciplinas_envolvidas = set()
for hab in relatorio_completo:
    for similar in hab['habilidades_similares']:
        disciplinas_envolvidas.add(similar['curriculo_eixo'])

print(f"ï¿½ Disciplinas envolvidas no mapeamento: {sorted(disciplinas_envolvidas)}")

# Verificar se os cÃ³digos estÃ£o sendo extraÃ­dos corretamente
print("\nğŸ” VERIFICAÃ‡ÃƒO FINAL DOS CÃ“DIGOS EXTRAÃDOS:")
print("-" * 50)
for i in range(min(3, len(relatorio_completo))):
    hab = relatorio_completo[i]
    print(f"BNCC {i+1}: {hab['bncc_codigo']}")
    print(f"Objetivo: {hab['bncc_objetivo'][:80]}...")
    print(f"Nota de corte usada: {hab['nota_corte_usada']:.1%}")
    print(f"Similaridades encontradas: {hab['quantidade_similares']}")
    print(f"Disciplinas envolvidas: {hab.get('disciplinas_envolvidas', 'N/A')}")
    if hab['habilidades_similares']:
        print(f"Melhor match: {hab['habilidades_similares'][0]['curriculo_codigo']} ({hab['habilidades_similares'][0]['similaridade']:.1%})")
        print(f"Disciplina: {hab['habilidades_similares'][0]['curriculo_eixo']}")
    print("-" * 30)

# ==================================================================================
#                           FUNÃ‡Ã•ES DE GERAÃ‡ÃƒO DE RELATÃ“RIOS
# ==================================================================================

def gerar_relatorio_texto():
    # Calcular estatÃ­sticas adicionais para o relatÃ³rio
    codigos_unicos_usados = set()
    disciplinas_usadas = {}
    
    for hab_bncc in relatorio_completo:
        for similar in hab_bncc['habilidades_similares']:
            codigos_unicos_usados.add(similar['curriculo_codigo'])
            disc = similar['curriculo_eixo']
            disciplinas_usadas[disc] = disciplinas_usadas.get(disc, 0) + 1
    
    relatorio_txt = f"""
==================================================================================
                    RELATÃ“RIO DE SIMILARIDADE BNCC x CURRÃCULO MUNICIPAL
==================================================================================
Data do relatÃ³rio: {estatisticas['data_analise']}
Nota de corte inicial: {estatisticas['nota_corte_original']*100}% de similaridade
Modelo utilizado: {estatisticas['modelo_usado']}
Algoritmo: BALANCEADO POR DISCIPLINAS (evita duplicatas de cÃ³digos)

ESTATÃSTICAS GERAIS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ Total de habilidades BNCC analisadas: {estatisticas['total_bncc']}
â€¢ Habilidades BNCC com similaridade â‰¥ {estatisticas['nota_corte_original']*100}% (nota original): {estatisticas['bncc_com_similaridade_original']} ({estatisticas['bncc_com_similaridade_original']/estatisticas['total_bncc']*100:.1f}%)
â€¢ Habilidades BNCC com correspondÃªncia (algoritmo balanceado): {estatisticas['bncc_com_similaridade_adaptativa']} ({estatisticas['bncc_com_similaridade_adaptativa']/estatisticas['total_bncc']*100:.1f}%)
â€¢ Total de matches acima da nota de corte original: {estatisticas['total_matches_acima_corte']}
â€¢ Habilidades Ãºnicas do currÃ­culo utilizadas: {len(codigos_unicos_usados)} de {len(curriculo_df_inf)} ({len(codigos_unicos_usados)/len(curriculo_df_inf)*100:.1f}%)
â€¢ Nota de corte mÃ©dia usada: {np.mean(estatisticas['notas_corte_usadas']):.1%}
â€¢ Nota de corte mÃ­nima usada: {np.min(estatisticas['notas_corte_usadas']):.1%}

DISTRIBUIÃ‡ÃƒO POR DISCIPLINAS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""

    for disc in sorted(disciplinas_usadas.keys()):
        count = disciplinas_usadas[disc]
        relatorio_txt += f"\nâ€¢ {disc}: {count} correspondÃªncias"

    relatorio_txt += f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

BENEFÃCIOS DO ALGORITMO BALANCEADO:
â€¢ Evita duplicatas: Cada cÃ³digo de habilidade do currÃ­culo Ã© usado no mÃ¡ximo uma vez
â€¢ DistribuiÃ§Ã£o equilibrada: Garante representaÃ§Ã£o de mÃºltiplas disciplinas
â€¢ Qualidade mantida: Prioriza correspondÃªncias com maior similaridade
â€¢ AnÃ¡lise crÃ­tica: Permite que educadores avaliem e refinem as correspondÃªncias

RELATÃ“RIO DETALHADO POR HABILIDADE BNCC:

"""
    
    for idx, habilidade in enumerate(relatorio_completo):
        relatorio_txt += f"""
{'='*80}
HABILIDADE BNCC #{habilidade['bncc_indice']} - {habilidade['bncc_codigo']}
{'='*80}

EIXO BNCC: {habilidade['bncc_eixo']}

OBJETIVO BNCC: {habilidade['bncc_objetivo']}

EXEMPLOS BNCC: {habilidade['bncc_exemplos']}

NOTA DE CORTE USADA: {habilidade['nota_corte_usada']:.1%} {'(original)' if habilidade['tem_similaridade_original'] else '(adaptativa)'}
QUANTIDADE DE HABILIDADES SIMILARES: {habilidade['quantidade_similares']}
MAIOR SIMILARIDADE ENCONTRADA: {habilidade['maior_similaridade']:.1%}

"""
        
        relatorio_txt += "HABILIDADES SIMILARES DO CURRÃCULO:\n"
        relatorio_txt += "-" * 60 + "\n"
        
        for i, similar in enumerate(habilidade['habilidades_similares'], 1):
            relatorio_txt += f"""
{i}. CURRÃCULO #{similar['curriculo_indice']} - {similar['curriculo_codigo']} | SIMILARIDADE: {similar['similaridade']:.1%}
   
   DISCIPLINA: {similar['curriculo_eixo']}
   
   HABILIDADE: {similar['curriculo_objetivo']}
   
   ORIENTAÃ‡Ã•ES PEDAGÃ“GICAS: {similar['curriculo_exemplos']}
   
   {'â”€' * 50}
"""
    
    return relatorio_txt

def gerar_relatorio_csv():
    dados_csv = []
    
    for habilidade in relatorio_completo:
        # Com a busca adaptativa, todas as habilidades terÃ£o pelo menos uma correspondÃªncia
        for similar in habilidade['habilidades_similares']:
            dados_csv.append({
                'BNCC_Indice': habilidade['bncc_indice'],
                'BNCC_Codigo': habilidade['bncc_codigo'],
                'BNCC_Eixo': habilidade['bncc_eixo'],
                'BNCC_Objetivo': habilidade['bncc_objetivo'],
                'BNCC_Exemplos': habilidade['bncc_exemplos'],
                'Curriculo_Indice': similar['curriculo_indice'],
                'Curriculo_Codigo': similar['curriculo_codigo'],
                'Curriculo_Eixo': similar['curriculo_eixo'],
                'Curriculo_Objetivo': similar['curriculo_objetivo'],
                'Curriculo_Exemplos': similar['curriculo_exemplos'],
                'Similaridade': similar['similaridade'],
                'Similaridade_Percentual': f"{similar['similaridade']:.1%}",
                'Nota_Corte_Usada': f"{habilidade['nota_corte_usada']:.1%}",
                'Busca_Adaptativa': 'NÃ£o' if habilidade['tem_similaridade_original'] else 'Sim',
                'Data_Analise': estatisticas['data_analise']
            })
    
    return pd.DataFrame(dados_csv)

def gerar_resumo_executivo():
    # Calcular estatÃ­sticas de distribuiÃ§Ã£o por disciplina
    disciplinas_usadas = {}
    total_habilidades_curriculo = len(curriculo_df_inf)
    
    for hab_bncc in relatorio_completo:
        for similar in hab_bncc['habilidades_similares']:
            disc = similar['curriculo_eixo']
            disciplinas_usadas[disc] = disciplinas_usadas.get(disc, 0) + 1
    
    # Calcular habilidades Ãºnicas utilizadas
    codigos_unicos_usados = set()
    for hab_bncc in relatorio_completo:
        for similar in hab_bncc['habilidades_similares']:
            codigos_unicos_usados.add(similar['curriculo_codigo'])
    
    resumo = f"""
==================================================================================
                            RESUMO EXECUTIVO
==================================================================================
Data: {estatisticas['data_analise']}
Nota de corte inicial: {estatisticas['nota_corte_original']*100}%
Algoritmo: BALANCEADO POR DISCIPLINAS (sem duplicatas)
Modelo: {estatisticas['modelo_usado']}

PRINCIPAIS DESCOBERTAS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ {estatisticas['bncc_com_similaridade_original']} de {estatisticas['total_bncc']} habilidades da BNCC ({estatisticas['bncc_com_similaridade_original']/estatisticas['total_bncc']*100:.1f}%) tÃªm correspondÃªncia com nota de corte original â‰¥ {estatisticas['nota_corte_original']*100}%

â€¢ {estatisticas['bncc_com_similaridade_adaptativa']} de {estatisticas['total_bncc']} habilidades da BNCC ({estatisticas['bncc_com_similaridade_adaptativa']/estatisticas['total_bncc']*100:.1f}%) tÃªm correspondÃªncia usando algoritmo balanceado

â€¢ Total de {estatisticas['total_matches_acima_corte']} conexÃµes identificadas acima da nota de corte original

â€¢ {len(codigos_unicos_usados)} habilidades Ãºnicas do currÃ­culo utilizadas de {total_habilidades_curriculo} disponÃ­veis ({len(codigos_unicos_usados)/total_habilidades_curriculo*100:.1f}%)

â€¢ Nota de corte mÃ©dia usada: {np.mean(estatisticas['notas_corte_usadas']):.1%}
â€¢ Nota de corte mÃ­nima usada: {np.min(estatisticas['notas_corte_usadas']):.1%}

DISTRIBUIÃ‡ÃƒO POR DISCIPLINAS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
    
    for disc in sorted(disciplinas_usadas.keys()):
        count = disciplinas_usadas[disc]
        resumo += f"â€¢ {disc}: {count} correspondÃªncias\n"
    
    resumo += f"""
HABILIDADES BNCC COM MAIOR NÃšMERO DE CORRESPONDÃŠNCIAS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
    
    top_correspondencias = sorted(relatorio_completo, key=lambda x: x['quantidade_similares'], reverse=True)[:CONFIGURACOES['MOSTRAR_TOP_CORRESPONDENCIAS']]
    
    for i, hab in enumerate(top_correspondencias, 1):
        disciplinas_envolvidas = hab.get('disciplinas_envolvidas', 'N/A')
        resumo += f"\n{i:2d}. {hab['bncc_codigo']} - {hab['quantidade_similares']} correspondÃªncias ({disciplinas_envolvidas} disciplinas)"
        resumo += f"\n    {hab['bncc_eixo']}"
        resumo += f"\n    Nota de corte usada: {hab['nota_corte_usada']:.1%} {'(original)' if hab['tem_similaridade_original'] else '(adaptativa)'}"
        resumo += f"\n    MÃ¡x. similaridade: {hab['maior_similaridade']:.1%}"
    
    resumo += f"\n\nHABILIDADES QUE PRECISARAM DE ALGORITMO ADAPTATIVO:\n"
    resumo += "â”" * 70 + "\n"
    
    busca_adaptativa = [h for h in relatorio_completo if not h['tem_similaridade_original']]
    if busca_adaptativa:
        for hab in busca_adaptativa:
            resumo += f"\nâ€¢ {hab['bncc_codigo']} - {hab['bncc_eixo']}"
            resumo += f"\n  Nota de corte usada: {hab['nota_corte_usada']:.1%}"
            resumo += f"\n  MÃ¡x. similaridade: {hab['maior_similaridade']:.1%}"
            resumo += f"\n  Disciplinas envolvidas: {hab.get('disciplinas_envolvidas', 'N/A')}"
            resumo += f"\n  {hab['bncc_objetivo'][:100]}{'...' if len(hab['bncc_objetivo']) > 100 else ''}\n"
    else:
        resumo += "\nâœ… Nenhuma habilidade precisou de algoritmo adaptativo - todas tiveram correspondÃªncia com nota de corte original!\n"
    
    resumo += f"""
BENEFÃCIOS DO ALGORITMO BALANCEADO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Sem duplicatas: Cada habilidade do currÃ­culo Ã© usada no mÃ¡ximo uma vez
âœ… DistribuiÃ§Ã£o equilibrada: Representa mÃºltiplas disciplinas nas correspondÃªncias
âœ… Qualidade mantida: Prioriza correspondÃªncias com maior similaridade
âœ… Flexibilidade: Permite anÃ¡lise crÃ­tica pelos educadores para refinamento
"""
    
    return resumo

# ==================================================================================
#                           SALVAMENTO DOS ARQUIVOS
# ==================================================================================

# Criar pasta docs/anos iniciais se nÃ£o existir
docs_path = os.path.join("docs", "anos iniciais")
if not os.path.exists(docs_path):
    os.makedirs(docs_path)
    print(f"ğŸ“ Pasta '{docs_path}' criada para organizar os relatÃ³rios")

nome_relatorio_completo = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}relatorio_completo.txt")
nome_relatorio_csv = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}relatorio.csv")
nome_resumo = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}resumo_executivo.txt")
nome_heatmap = os.path.join(docs_path, f"anosiniciais_{CONFIGURACOES['PREFIXO_ARQUIVOS']}heatmap_similaridade.png")

try:
    # RelatÃ³rio completo em texto
    with open(nome_relatorio_completo, "w", encoding="utf-8") as f:
        f.write(gerar_relatorio_texto())
    
    # RelatÃ³rio em CSV
    df_csv = gerar_relatorio_csv()
    df_csv.to_csv(nome_relatorio_csv, index=False, encoding="utf-8-sig")
    
    # Resumo executivo
    with open(nome_resumo, "w", encoding="utf-8") as f:
        f.write(gerar_resumo_executivo())
    
    print("âœ… RelatÃ³rios salvos com sucesso!")
    print(f"   ğŸ“„ {nome_relatorio_completo} - RelatÃ³rio detalhado completo")
    print(f"   ğŸ“Š {nome_relatorio_csv} - Dados em formato CSV")
    print(f"   ğŸ“‹ {nome_resumo} - Resumo com principais descobertas")
    
except Exception as e:
    print(f"âŒ Erro ao salvar relatÃ³rios: {e}")

# Gerar heatmap se configurado
if CONFIGURACOES['GERAR_HEATMAP']:
    try:
        # Extrai cÃ³digos para usar como Ã­ndices (usando as colunas corretas)
        bncc_codigos = bncc_df_inf['HABILIDADE'].apply(extrair_codigo).tolist()
        curriculo_codigos = curriculo_df_inf['HABILIDADES'].apply(extrair_codigo).tolist()
        
        # Cria DataFrame de similaridade
        sim_df = pd.DataFrame(grau_similaridade, 
                              index=bncc_codigos,
                              columns=curriculo_codigos)
        
        # Gera heatmap com tamanho configurÃ¡vel
        tamanho_h, tamanho_c = CONFIGURACOES['TAMANHO_HEATMAP']
        plt.figure(figsize=(16, 10))
        sns.heatmap(
            sim_df.iloc[:tamanho_h, :tamanho_c],
            annot=True,
            fmt=".2f",
            cmap="Blues",
            vmin=0, vmax=1,
            cbar_kws={'label': 'Similaridade'}
        )
        plt.title(f"Heatmap de Similaridade BNCC x CurrÃ­culo Municipal\nNota de corte: {CONFIGURACOES['NOTA_CORTE']*100}%")
        plt.xlabel("CurrÃ­culo (cÃ³digos)")
        plt.ylabel("BNCC (cÃ³digos)")
        plt.tight_layout()
        plt.savefig(nome_heatmap, dpi=300, bbox_inches='tight')
        print(f"   ğŸ¨ {nome_heatmap} - Heatmap de similaridade")
    except Exception as e:
        print(f"âš ï¸  Aviso: NÃ£o foi possÃ­vel gerar o heatmap: {e}")

# ==================================================================================
#                           EXIBIÃ‡ÃƒO NO TERMINAL
# ==================================================================================

# Exibir resumo no terminal
print("\n" + "="*80)
print("ğŸ“Š RESUMO DA ANÃLISE:")
print("="*80)
print(f"âœ… AnÃ¡lise concluÃ­da com sucesso!")
print(f"âš™ï¸  Nota de corte inicial: {CONFIGURACOES['NOTA_CORTE']*100}%")
print(f"ğŸ“Š {estatisticas['bncc_com_similaridade_original']}/{estatisticas['total_bncc']} habilidades BNCC tÃªm correspondÃªncia â‰¥ {CONFIGURACOES['NOTA_CORTE']*100}%")
print(f"ï¿½ {estatisticas['bncc_com_similaridade_adaptativa']}/{estatisticas['total_bncc']} habilidades BNCC tÃªm correspondÃªncia com busca adaptativa")
print(f"ï¿½ğŸ” {estatisticas['total_matches_acima_corte']} conexÃµes identificadas acima da nota de corte original")
print(f"ğŸ“ˆ Nota de corte mÃ©dia usada: {np.mean(estatisticas['notas_corte_usadas']):.1%}")
print(f"ğŸ“‰ Nota de corte mÃ­nima usada: {np.min(estatisticas['notas_corte_usadas']):.1%}")

# Mostrar algumas das melhores correspondÃªncias no terminal
print(f"\nğŸ† TOP {CONFIGURACOES['MOSTRAR_TOP_MATCHES_TERMINAL']} MELHORES CORRESPONDÃŠNCIAS:")
print("-" * 70)

todos_matches = []
for hab in relatorio_completo:
    for similar in hab['habilidades_similares']:
        todos_matches.append({
            'bncc_codigo': hab['bncc_codigo'],
            'curriculo_codigo': similar['curriculo_codigo'],
            'similaridade': similar['similaridade'],
            'bncc_eixo': hab['bncc_eixo'],
            'curriculo_eixo': similar['curriculo_eixo']
        })

top_matches = sorted(todos_matches, key=lambda x: x['similaridade'], reverse=True)[:CONFIGURACOES['MOSTRAR_TOP_MATCHES_TERMINAL']]

for i, match in enumerate(top_matches, 1):
    print(f"{i:2d}. {match['bncc_codigo']} â†” {match['curriculo_codigo']} | {match['similaridade']:.1%}")
    print(f"    BNCC: {match['bncc_eixo']}")
    print(f"    CurrÃ­culo: {match['curriculo_eixo']}")
    print()

print("="*80)
print("ğŸ’¡ DICA: Para alterar a nota de corte inicial, modifique CONFIGURACOES['NOTA_CORTE'] no topo do script!")
print("ğŸ”§ A busca adaptativa garante que toda habilidade BNCC tenha pelo menos uma correspondÃªncia!")
print("ğŸ“ Consulte os arquivos de relatÃ³rio para anÃ¡lise completa!")
print("="*80)